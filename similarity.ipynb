{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from nltk.stem import SnowballStemmer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_set = ['r','python','java','c++','ruby','perl','matlab','javascript','scala','excel','tableau',\n",
    "             'd3js','sas','spss','d3','hadoop','mapreduce','spark',\n",
    "             'pig','hive','shark','zookeeper','flume','mahout',\n",
    "             'sql','nosql','hase','cassandra','mongodb','docker','aws']\n",
    "ideal_text = ['applies',\n",
    " 'developed',\n",
    " 'subject',\n",
    " 'matter',\n",
    " 'knowledge',\n",
    " 'solve',\n",
    " 'common',\n",
    " 'complex',\n",
    " 'business',\n",
    " 'issues',\n",
    " 'within',\n",
    " 'established',\n",
    " 'guidelines',\n",
    " 'recommends',\n",
    " 'appropriate',\n",
    " 'alternatives',\n",
    " 'works',\n",
    " 'problems',\n",
    " 'diverse',\n",
    " 'complexity',\n",
    " 'scope',\n",
    " 'may',\n",
    " 'act',\n",
    " 'team',\n",
    " 'project',\n",
    " 'leader',\n",
    " 'providing',\n",
    " 'direction',\n",
    " 'team',\n",
    " 'activities',\n",
    " 'facilitates',\n",
    " 'information',\n",
    " 'validation',\n",
    " 'team',\n",
    " 'decision',\n",
    " 'making',\n",
    " 'process',\n",
    " 'exercises',\n",
    " 'independent',\n",
    " 'judgment',\n",
    " 'within',\n",
    " 'generally',\n",
    " 'defined',\n",
    " 'policies',\n",
    " 'practices',\n",
    " 'identify',\n",
    " 'select',\n",
    " 'solution',\n",
    " 'ability',\n",
    " 'handle',\n",
    " 'unique',\n",
    " 'situations',\n",
    " 'may',\n",
    " 'seek',\n",
    " 'advice',\n",
    " 'order',\n",
    " 'make',\n",
    " 'decisions',\n",
    " 'complex',\n",
    " 'business',\n",
    " 'issues',\n",
    " 'responsibilities',\n",
    " 'design',\n",
    " 'implement',\n",
    " 'qa',\n",
    " 'deploy',\n",
    " 'document',\n",
    " 'web',\n",
    " 'analytics',\n",
    " 'solutions',\n",
    " 'using',\n",
    " 'tag',\n",
    " 'managers',\n",
    " 'analytics',\n",
    " 'tools',\n",
    " 'diagnose',\n",
    " 'resolve',\n",
    " 'complex',\n",
    " 'analytics',\n",
    " 'data',\n",
    " 'collection',\n",
    " 'anomalies',\n",
    " 'using',\n",
    " 'analytics',\n",
    " 'testing',\n",
    " 'tools',\n",
    " 'methodologies',\n",
    " 'collaborate',\n",
    " 'stakeholders',\n",
    " 'solution',\n",
    " 'providers',\n",
    " 'development',\n",
    " 'teams',\n",
    " 'design',\n",
    " 'develop',\n",
    " 'publish',\n",
    " 'analytics',\n",
    " 'solutions',\n",
    " 'document',\n",
    " 'new',\n",
    " 'existing',\n",
    " 'web',\n",
    " 'analytics',\n",
    " 'solutions',\n",
    " 'developers',\n",
    " 'data',\n",
    " 'analysts',\n",
    " 'configure',\n",
    " 'manage',\n",
    " 'analytics',\n",
    " 'solutions',\n",
    " 'google',\n",
    " 'analytics',\n",
    " 'google',\n",
    " 'tag',\n",
    " 'manager',\n",
    " 'adobe',\n",
    " 'analytics',\n",
    " 'ensighten',\n",
    " 'qualifications',\n",
    " 'required',\n",
    " 'experience',\n",
    " 'developing',\n",
    " 'custom',\n",
    " 'google',\n",
    " 'analytics',\n",
    " 'solutions',\n",
    " 'ga360',\n",
    " 'experience',\n",
    " 'developing',\n",
    " 'custom',\n",
    " 'adobe',\n",
    " 'analytics',\n",
    " 'eg',\n",
    " '“omniture”',\n",
    " '“site',\n",
    " 'catalyst”',\n",
    " 'solutions',\n",
    " 'including',\n",
    " 'adobe',\n",
    " 'analytics',\n",
    " 'admin',\n",
    " 'experience',\n",
    " 'experience',\n",
    " 'designing',\n",
    " 'developing',\n",
    " 'digital',\n",
    " 'data',\n",
    " 'layers',\n",
    " 'including',\n",
    " 'google',\n",
    " 'data',\n",
    " 'layer',\n",
    " 'enhanced',\n",
    " 'e',\n",
    " 'commerce',\n",
    " 'experience',\n",
    " 'google',\n",
    " 'tag',\n",
    " 'manger',\n",
    " 'experience',\n",
    " 'ensighten',\n",
    " 'manage',\n",
    " '3',\n",
    " 'years',\n",
    " 'advanced',\n",
    " 'development',\n",
    " 'experience',\n",
    " 'including',\n",
    " 'object',\n",
    " 'oriented',\n",
    " 'programming',\n",
    " 'script',\n",
    " 'experience',\n",
    " 'developing',\n",
    " 'document',\n",
    " 'object',\n",
    " 'model',\n",
    " 'dom',\n",
    " 'html',\n",
    " 'including',\n",
    " 'single',\n",
    " 'page',\n",
    " 'apps',\n",
    " 'bachelors',\n",
    " 'degree',\n",
    " 'field',\n",
    " 'study',\n",
    " 'computer',\n",
    " 'science',\n",
    " 'information',\n",
    " 'systems',\n",
    " 'related',\n",
    " 'field',\n",
    " 'ability',\n",
    " 'work',\n",
    " 'normal',\n",
    " 'business',\n",
    " 'hours',\n",
    " 'us',\n",
    " 'central',\n",
    " 'time',\n",
    " 'plus',\n",
    " 'time',\n",
    " 'outside',\n",
    " 'normal',\n",
    " 'business',\n",
    " 'hours',\n",
    " 'teleconference',\n",
    " 'international',\n",
    " 'teams',\n",
    " 'emergency',\n",
    " 'trouble',\n",
    " 'shooting',\n",
    " 'lipost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NY', 'OH', 'Remote', 'States', 'CA', 'NJ', 'NC', 'MO', 'FL', 'PA',\n",
       "       'VA', 'State', 'MA', 'CT', 'GA', 'OR', 'DC', 'TX', 'IL', 'WA',\n",
       "       'Kansas', 'CO', 'TN', 'UT', 'MD', 'RI', 'MN', 'AZ', 'LA', 'DE',\n",
       "       'MI', 'NV', 'ID', 'IA', 'unavailable', 'IN', 'Based', 'California',\n",
       "       'Mississippi'], dtype=object)"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CHECK FOR CLEANING\n",
    "\n",
    "#df_ds = pd.read_csv('data_scientist.csv') \n",
    "#df_ds.head()\n",
    "\n",
    "\n",
    "#df_mle = pd.read_csv('machine_learning_engineer.csv')\n",
    "#df_mle.head\n",
    "\n",
    "\n",
    "#df_sd = pd.read_csv('softwate_developer.csv')\n",
    "#df_sd.head()\n",
    "#df_sd.city.unique() #united states error\n",
    "#df_sd.state.unique() # 'Pennsylvania', 'Arkansas', 'Florida','California', 'Tennessee', 'Home', 'Based\n",
    "#df_sd[df_sd['desc'] == \"['U', 'n', 'a', 'v', 'a', 'i', 'l', 'a', 'b', 'l', 'e']\"] #none only 1 company name unaivailable\n",
    "\n",
    "\n",
    "#df_fsd = pd.read_csv('full_stack_developer.csv')\n",
    "#df_fsd.city.unique() \n",
    "#df_fsd.state.unique() # 'California', 'Texas', 'Connecticut', 'States', 'Remote'\n",
    "#df_fsd[df_sd['desc'] == \"['U', 'n', 'a', 'v', 'a', 'i', 'l', 'a', 'b', 'l', 'e']\"] #none \n",
    "#df_fsd[df_fsd['company'] == \"unavailable\"] # one\n",
    "#df_fsd[df_fsd['city'] == \"unavailable\"] #none none for state\n",
    "\n",
    "# df_bia = pd.read_csv('business_intelligence_analyst.csv')\n",
    "# df_bia.city.unique() #Nort = Chapel Hill NC\n",
    "# df_bia[df_bia['city'] == 'Nort']\n",
    "# df_bia.state.unique() \n",
    "# df_bia[df_bia['desc'] == \"['U', 'n', 'a', 'v', 'a', 'i', 'l', 'a', 'b', 'l', 'e']\"] #none \n",
    "# df_bia[df_bia['company'] == \"unavailable\"] # none\n",
    "# df_bia[df_bia['state'] == \"unavailable\"] #none none for state\n",
    "\n",
    "# df_de = pd.read_csv('data_engineer.csv')\n",
    "# df_de.city.unique() # Home  = Home Based = Remote\n",
    "# df_de.state.unique() #'Based' 'Texas' 'Pennsylvania' 'unavailable' 'Alabama'\n",
    "# df_de[df_de['state'] == 'Based'].url.values #Based = Home Based make city and \n",
    "# df_de[df_de['state']=='unavailable']\n",
    "# df_de[df_de['desc'] == \"['U', 'n', 'a', 'v', 'a', 'i', 'l', 'a', 'b', 'l', 'e']\"] #two \n",
    "#df_de[df_de.isnull()].shape #3580 null values\n",
    "\n",
    "# df_da = pd.read_csv('data_architect.csv')\n",
    "# df_da.city.unique()\n",
    "# df_da.state.unique() #'California', 'Massachusetts', 'Georgia, 'Florida' 'California' 'State' 'unavailable'\n",
    "# df_da[df_da['state'] == 'unavailable'] # city = New Yor state = State\n",
    "# df_de[df_de['desc'] == \"['U', 'n', 'a', 'v', 'a', 'i', 'l', 'a', 'b', 'l', 'e']\"]\n",
    "\n",
    "\n",
    "#df_dev = pd.read_csv('dev_ops.csv')\n",
    "# df_dev.city.unique() # nan ada\n",
    "# df_dev['city'] = df_dev.city.fillna('Remote')\n",
    "# df_dev[df_dev['city'] == 'Remote']\n",
    "#df_dev.state.unique() # island \n",
    "#df_dev[df_dev['state'] == 'Island']\n",
    "\n",
    "# df_py = pd.read_csv('python.csv')\n",
    "# df_py.city.unique()\n",
    "# df_py = df_py.reset_index(drop=True)\n",
    "# l = df_py[df_py.city.isnull()]\n",
    "# l = l[l['state'] != 'Remote']\n",
    "# df_py.state.unique()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ds = pd.read_csv('data_scientist.csv') \n",
    "#df_mle = pd.read_csv('machine_learning_engineer.csv')\n",
    "#df_sd = pd.read_csv('softwate_developer.csv')\n",
    "#df_fsd = pd.read_csv('full_stack_developer.csv')\n",
    "#df_bia = pd.read_csv('business_intelligence_analyst.csv')\n",
    "#df_de = pd.read_csv('data_engineer.csv')\n",
    "#df_da = pd.read_csv('data_architect.csv')\n",
    "#df_py = pd.read_csv('python.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfList = [df_ds,df_mle,df_sd,df_fsd,df_bia,df_de,df_da,df_dev,df_py]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_dfs(dfList):\n",
    "    return reduce(lambda x, y: x.append(y), dfList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56180, 9)"
      ]
     },
     "execution_count": 785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_df = join_dfs(dfList)\n",
    "joint_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_skills = joint_df['desc'].values\n",
    "job_skills = [ast.literal_eval(x) for x in job_skills]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHARGE SOFTWARE DEVELOPER NAME \n",
    "def format_df(df): \n",
    "    \n",
    "    #dropping unnamed \n",
    "    df = df.iloc[:,1:]\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    #dropping duplicated rows\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.reset_index(drop=True)\n",
    "       \n",
    "    #getting rid of jobs that have no descriptions \n",
    "    index = df[df['desc'] == \"['U', 'n', 'a', 'v', 'a', 'i', 'l', 'a', 'b', 'l', 'e']\"].index\n",
    "    df = df.drop(index,axis = 0)\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    #nan cities are remote\n",
    "    df['city'] = df.city.fillna('Multiple')\n",
    "    \n",
    "    #formatting for alternate locations \n",
    "    df['city'] = df.city.apply(lambda x: 'Multiple' if x == \"Unite\" else x)\n",
    "    df['city'] = df.city.apply(lambda x: 'unavailable' if x == \"unavailabl\" else x)\n",
    "    df['city'] = df.city.apply(lambda x: 'unavailable' if x == \"unavailabl\" else x)\n",
    "    df['city'] = df.city.apply(lambda x: 'Chapel Hill' if x == \"Nort\" else x)\n",
    "    df['city'] = df.city.apply(lambda x: 'Remote' if x == \"Hom\" else x)\n",
    "    df['city'] = df.city.apply(lambda x: 'Remote' if x == \"Home\" else x)\n",
    "    df['city'] = df.city.apply(lambda x: 'New York' if x == \"New Yor\" else x)\n",
    "    df['city'] = df.city.apply(lambda x: 'San Juan' if x == \"Puert\" else x)\n",
    "    df['city'] = df.city.apply(lambda x: 'Multiple' if x == \"Rhod\" else x)\n",
    "\n",
    "     \n",
    "    df['state'] = df.state.apply(lambda x: 'Multiple' if x == \"States\" else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'NY' if x == \"State\" else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'Remote' if x == \"Home\" else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'Remote' if x == \"Based\" else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'MN' if x == 'Minnesota' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'AZ' if x == 'Arizona' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'PA' if x == 'Pennsylvania' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'FL' if x == 'Florida' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'CA' if x == 'California' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'TN' if x == 'Tennessee' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'AR' if x == 'Arkansas' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'TX' if x == 'Texas' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'CT' if x == 'Connecticut' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'NC' if x == 'Carolina' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'AL' if x == 'Alabama' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'MA' if x == 'Massachusetts' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'GA' if x == 'Georgia' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'IL' if x == 'Illinois' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'VA' if x == 'Virginia' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'PR' if x == 'Rico' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'KS' if x == 'Kansas' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'RI' if x == 'Island' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'MS' if x == 'Mississippi' else x)\n",
    "    \n",
    "    \n",
    "    #filling nan\n",
    "    df.fillna('unavailable')\n",
    "    \n",
    "    #stemming\n",
    "    #return the model and the df \n",
    "    \n",
    "    \n",
    "    #STEM when you're making the data_frame because it takes too long here \n",
    " \n",
    "    return model, df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_df = format_df(joint_df) #write this into a csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6427, 8)"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_df(df,job = None, city = None, state = None, skills = None, stringency = None):\n",
    "    '''\n",
    "    skills = list \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    if job != None:\n",
    "        \n",
    "        jobs_available = formatted_df.job.unique()\n",
    "        \n",
    "        if job not in jobs_available:\n",
    "            return 'Job Unavailable'\n",
    "        \n",
    "        df = df[df['job'] == 'Data Scientist']\n",
    "        \n",
    "    if city != None:\n",
    "        cities_available = formatted_df.city.unique()\n",
    "        \n",
    "        if city not in cities_available:\n",
    "            return 'City Unavailable'\n",
    "        else:\n",
    "            df = df[df['city'].isin([city,'Multiple'])]\n",
    "    \n",
    "    if state != None:\n",
    "        \n",
    "        states_available = formatted_df.state.unique()\n",
    "        \n",
    "        if state not in states_available:\n",
    "            return 'State Unavailable'\n",
    "\n",
    "        df = df[df['state'].isin([state,'Multiple'])]\n",
    "    \n",
    "    \n",
    "    \n",
    "    if skills != None:\n",
    "        \n",
    "        job_skills = df.skills.values\n",
    "        job_skills = [ast.literal_eval(x) for x in job_skills]\n",
    "        indexes = []\n",
    "        \n",
    "        if stringency == 'all':\n",
    "            for i,job in enumerate(job_skills):\n",
    "                if skills == job:\n",
    "                    indexes.append(i)\n",
    "                \n",
    "            df = df.iloc[indexes,:]\n",
    "            \n",
    "            #need to do the ones for only r only python etc \n",
    "        \n",
    "        elif stringency == 'only':\n",
    "            for i, job in enumerate(job_skills):\n",
    "                if set(job).issubset(skills):\n",
    "                    indexes.append(i)\n",
    "            \n",
    "            df = df.iloc[indexes,:]\n",
    "            \n",
    "        elif stringency == 'atleast':\n",
    "            for i, job in enumerate(job_skills):\n",
    "                if set(skills).issubset(job):\n",
    "                    indexes.append(i)\n",
    "            \n",
    "            df = df.iloc[indexes,:]\n",
    "    \n",
    "    if df.empty == True:\n",
    "        return 'There are no jobs available for this combination'\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = get_query_df(formatted_df,'Data Scientist',city = 'New York',state = 'NY',skills = 'python','only')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GOT QUERY TEXT FROM INDEED DOCUMENT\n",
    "\n",
    "# def get_ideal_text(skill_set,ideal_url):\n",
    "    \n",
    "#     _, _, _,_, job_description = get_job_info(ideal_url)\n",
    "#     text_no_skills, _ = clean_job_description(job_description,skill_set)\n",
    "    \n",
    "#     #job_title, company_name, city[:-1], state, job_description\n",
    "    \n",
    "#     return text_no_skills\n",
    "\n",
    "# query_text = get_ideal_text(skill_set,'https://www.indeed.com/viewjob?jk=eafcd4523a84b235&tk=1d0d2d912ah4o804&from=serp&vjs=3')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_sim(ideal_text, query_df,num):\n",
    "    \n",
    "    ideal_words = [\" \".join(ideal_text)]\n",
    "    \n",
    "    job_words = df.desc.values\n",
    "    job_words = [ast.literal_eval(x) for x in job_words] #turns string into a list\n",
    "    job_words = [x for x in job_words if not isinstance(x, int)] #gets rid of numbers\n",
    "    \n",
    "    \n",
    "    stemmer = SnowballStemmer('english') #get rid if this if you're going to do semantic similary\n",
    "    job_words_stem = [] \n",
    "    for job in job_words:\n",
    "        job_words_stem.append([stemmer.stem(word) for word in job]) \n",
    "    \n",
    "    job_desc = [\" \".join(li) for li in job_words_stem]\n",
    "    \n",
    "    vectorizer = TfidfVectorizer() #make sure these defaults are correct\n",
    "    model = vectorizer.fit(job_desc)\n",
    "    \n",
    "    ideal_tfidf = model.transform(ideal_words)\n",
    "    job_tfidf = model.transform(job_desc)\n",
    "    \n",
    "    cosine_sim = cosine_similarity(ideal_tfidf,job_tfidf)\n",
    "    \n",
    "    #stem the ideal words here \n",
    "\n",
    "    if len(cosine_sim) <= num:\n",
    "        return cosine_sim.argsort()[0][::-1]\n",
    "    else:\n",
    "        return cosine_sim.argsort()[0][::-1][0:num]\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05075531, 0.02512695, 0.04409375, ..., 0.04610444, 0.04582912,\n",
       "        0.03073344]])"
      ]
     },
     "execution_count": 784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_sim(ideal_text, query_df,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_jobs(query_df,indices):\n",
    "    top_jobs = query_df.iloc[indices,:]\n",
    "    \n",
    "    #put in a quantifier ex. these jobs are very similiary or these jobs are not very similar \n",
    "    \n",
    "    return "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
