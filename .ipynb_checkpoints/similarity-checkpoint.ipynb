{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from nltk.stem import SnowballStemmer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from bs4 import BeautifulSoup\n",
    "import string \n",
    "from urllib.request import urlopen\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "from nltk.corpus import stopwords \n",
    "import re\n",
    "from scraping_code import get_job_info\n",
    "from scraping_code import clean_job_description\n",
    "from scraping_code import skill_set\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK FOR CLEANING\n",
    "\n",
    "#df_ds = pd.read_csv('data_scientist.csv') \n",
    "#df_ds.head()\n",
    "\n",
    "\n",
    "#df_mle = pd.read_csv('machine_learning_engineer.csv')\n",
    "#df_mle.head\n",
    "\n",
    "\n",
    "#df_sd = pd.read_csv('softwate_developer.csv')\n",
    "#df_sd.head()\n",
    "#df_sd.city.unique() #united states error\n",
    "#df_sd.state.unique() # 'Pennsylvania', 'Arkansas', 'Florida','California', 'Tennessee', 'Home', 'Based\n",
    "#df_sd[df_sd['desc'] == \"['U', 'n', 'a', 'v', 'a', 'i', 'l', 'a', 'b', 'l', 'e']\"] #none only 1 company name unaivailable\n",
    "\n",
    "\n",
    "#df_fsd = pd.read_csv('full_stack_developer.csv')\n",
    "#df_fsd.city.unique() \n",
    "#df_fsd.state.unique() # 'California', 'Texas', 'Connecticut', 'States', 'Remote'\n",
    "#df_fsd[df_sd['desc'] == \"['U', 'n', 'a', 'v', 'a', 'i', 'l', 'a', 'b', 'l', 'e']\"] #none \n",
    "#df_fsd[df_fsd['company'] == \"unavailable\"] # one\n",
    "#df_fsd[df_fsd['city'] == \"unavailable\"] #none none for state\n",
    "\n",
    "# df_bia = pd.read_csv('business_intelligence_analyst.csv')\n",
    "# df_bia.city.unique() #Nort = Chapel Hill NC\n",
    "# df_bia[df_bia['city'] == 'Nort']\n",
    "# df_bia.state.unique() \n",
    "# df_bia[df_bia['desc'] == \"['U', 'n', 'a', 'v', 'a', 'i', 'l', 'a', 'b', 'l', 'e']\"] #none \n",
    "# df_bia[df_bia['company'] == \"unavailable\"] # none\n",
    "# df_bia[df_bia['state'] == \"unavailable\"] #none none for state\n",
    "\n",
    "# df_de = pd.read_csv('data_engineer.csv')\n",
    "# df_de.city.unique() # Home  = Home Based = Remote\n",
    "# df_de.state.unique() #'Based' 'Texas' 'Pennsylvania' 'unavailable' 'Alabama'\n",
    "# df_de[df_de['state'] == 'Based'].url.values #Based = Home Based make city and \n",
    "# df_de[df_de['state']=='unavailable']\n",
    "# df_de[df_de['desc'] == \"['U', 'n', 'a', 'v', 'a', 'i', 'l', 'a', 'b', 'l', 'e']\"] #two \n",
    "#df_de[df_de.isnull()].shape #3580 null values\n",
    "\n",
    "# df_da = pd.read_csv('data_architect.csv')\n",
    "# df_da.city.unique()\n",
    "# df_da.state.unique() #'California', 'Massachusetts', 'Georgia, 'Florida' 'California' 'State' 'unavailable'\n",
    "# df_da[df_da['state'] == 'unavailable'] # city = New Yor state = State\n",
    "# df_de[df_de['desc'] == \"['U', 'n', 'a', 'v', 'a', 'i', 'l', 'a', 'b', 'l', 'e']\"]\n",
    "\n",
    "\n",
    "#df_dev = pd.read_csv('dev_ops.csv')\n",
    "# df_dev.city.unique() # nan ada\n",
    "# df_dev['city'] = df_dev.city.fillna('Remote')\n",
    "# df_dev[df_dev['city'] == 'Remote']\n",
    "#df_dev.state.unique() # island \n",
    "#df_dev[df_dev['state'] == 'Island']\n",
    "\n",
    "# df_py = pd.read_csv('python.csv')\n",
    "# df_py.city.unique()\n",
    "# df_py = df_py.reset_index(drop=True)\n",
    "# l = df_py[df_py.city.isnull()]\n",
    "# l = l[l['state'] != 'Remote']\n",
    "# df_py.state.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ideal_text(skill_set,ideal_url):\n",
    "    \n",
    "    _, _, _, _, job_description = get_job_info(ideal_url)\n",
    "    text_no_skills, _ = clean_job_description(job_description,skill_set)\n",
    "    \n",
    "    return text_no_skills\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_dfs(dfList):\n",
    "    return reduce(lambda x, y: x.append(y), dfList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df(df): \n",
    "    \n",
    "    #dropping unnamed \n",
    "    df = df.iloc[:,1:]\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    #dropping duplicated rows\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.reset_index(drop=True)\n",
    "       \n",
    "    #getting rid of jobs that have no descriptions \n",
    "    index = df[df['desc'] == \"['U', 'n', 'a', 'v', 'a', 'i', 'l', 'a', 'b', 'l', 'e']\"].index\n",
    "    df = df.drop(index,axis = 0)\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    #nan cities are remote\n",
    "    df['city'] = df.city.fillna('Multiple')\n",
    "    \n",
    "    #formatting for alternate locations \n",
    "    df['city'] = df.city.apply(lambda x: 'Multiple' if x == \"Unite\" else x)\n",
    "    df['city'] = df.city.apply(lambda x: 'unavailable' if x == \"unavailabl\" else x)\n",
    "    df['city'] = df.city.apply(lambda x: 'unavailable' if x == \"unavailabl\" else x)\n",
    "    df['city'] = df.city.apply(lambda x: 'Chapel Hill' if x == \"Nort\" else x)\n",
    "    df['city'] = df.city.apply(lambda x: 'Remote' if x == \"Hom\" else x)\n",
    "    df['city'] = df.city.apply(lambda x: 'Remote' if x == \"Home\" else x)\n",
    "    df['city'] = df.city.apply(lambda x: 'New York' if x == \"New Yor\" else x)\n",
    "    df['city'] = df.city.apply(lambda x: 'San Juan' if x == \"Puert\" else x)\n",
    "    df['city'] = df.city.apply(lambda x: 'Multiple' if x == \"Rhod\" else x)\n",
    "\n",
    "     \n",
    "    df['state'] = df.state.apply(lambda x: 'Multiple' if x == \"States\" else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'NY' if x == \"State\" else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'Remote' if x == \"Home\" else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'Remote' if x == \"Based\" else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'MN' if x == 'Minnesota' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'AZ' if x == 'Arizona' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'PA' if x == 'Pennsylvania' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'FL' if x == 'Florida' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'CA' if x == 'California' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'TN' if x == 'Tennessee' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'AR' if x == 'Arkansas' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'TX' if x == 'Texas' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'CT' if x == 'Connecticut' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'NC' if x == 'Carolina' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'AL' if x == 'Alabama' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'MA' if x == 'Massachusetts' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'GA' if x == 'Georgia' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'IL' if x == 'Illinois' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'VA' if x == 'Virginia' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'PR' if x == 'Rico' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'KS' if x == 'Kansas' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'RI' if x == 'Island' else x)\n",
    "    df['state'] = df.state.apply(lambda x: 'MS' if x == 'Mississippi' else x)\n",
    "    \n",
    "    \n",
    "    #filling nan\n",
    "    df.fillna('unavailable')\n",
    " \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_df(df,job = None, city = None, state = None, skills = None, stringency = None):\n",
    "    '''\n",
    "    skills = list \n",
    "    '''\n",
    "       \n",
    "    if job != None:\n",
    "        \n",
    "        jobs_available = formatted_df.job.unique()\n",
    "        \n",
    "        if job not in jobs_available:\n",
    "            return 'Job Unavailable'\n",
    "        \n",
    "        df = df[df['job'] == 'Data Scientist']\n",
    "        \n",
    "    if city != None:\n",
    "        cities_available = formatted_df.city.unique()\n",
    "        \n",
    "        if city not in cities_available:\n",
    "            return 'City Unavailable'\n",
    "        else:\n",
    "            df = df[df['city'].isin([city,'Multiple'])]\n",
    "    \n",
    "    if state != None:\n",
    "        \n",
    "        states_available = formatted_df.state.unique()\n",
    "        \n",
    "        if state not in states_available:\n",
    "            return 'State Unavailable'\n",
    "\n",
    "        df = df[df['state'].isin([state,'Multiple'])]\n",
    "    \n",
    "    \n",
    "    \n",
    "    if skills != None:\n",
    "        \n",
    "        job_skills = df.skills.values\n",
    "        job_skills = [ast.literal_eval(x) for x in job_skills]\n",
    "        indexes = []\n",
    "        \n",
    "        if stringency == 'all':\n",
    "            for i,job in enumerate(job_skills):\n",
    "                if skills == job:\n",
    "                    indexes.append(i)\n",
    "                \n",
    "            df = df.iloc[indexes,:]\n",
    "            \n",
    "            #need to do the ones for only r only python etc \n",
    "        \n",
    "        elif stringency == 'only':\n",
    "            for i, job in enumerate(job_skills):\n",
    "                if set(job).issubset(skills):\n",
    "                    indexes.append(i)\n",
    "            \n",
    "            df = df.iloc[indexes,:]\n",
    "            \n",
    "        elif stringency == 'atleast':\n",
    "            for i, job in enumerate(job_skills):\n",
    "                if set(skills).issubset(job):\n",
    "                    indexes.append(i)\n",
    "            \n",
    "            df = df.iloc[indexes,:]\n",
    "    \n",
    "    if df.empty == True:\n",
    "        return 'There are no jobs available for this combination'\n",
    "    \n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_sim(ideal_text, query_df,num):\n",
    "    \n",
    "    ideal_words = [\" \".join(ideal_text)]\n",
    "    \n",
    "    job_words = query_df.desc.values\n",
    "    job_words = [ast.literal_eval(x) for x in job_words] #turns string into a list\n",
    "    job_words = [x for x in job_words if not isinstance(x, int)] #gets rid of numbers\n",
    "    \n",
    "    \n",
    "    stemmer = SnowballStemmer('english') #get rid if this if you're going to do semantic similary\n",
    "    job_words_stem = [] \n",
    "    for job in job_words:\n",
    "        job_words_stem.append([stemmer.stem(word) for word in job]) \n",
    "    \n",
    "    job_desc = [\" \".join(li) for li in job_words_stem]\n",
    "    \n",
    "    vectorizer = TfidfVectorizer() #make sure these defaults are correct\n",
    "    model = vectorizer.fit(job_desc)\n",
    "    \n",
    "    ideal_tfidf = model.transform(ideal_words)\n",
    "    job_tfidf = model.transform(job_desc)\n",
    "    \n",
    "    cosine_sim = cosine_similarity(ideal_tfidf,job_tfidf)[0]\n",
    "\n",
    "    if len(cosine_sim) <= num:\n",
    "        return cosine_sim, cosine_sim.argsort()[::-1]\n",
    "    else:\n",
    "        return cosine_sim, cosine_sim.argsort()[::-1][0:num]\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_jobs(query_df,indices, cosine_sim):\n",
    "    \n",
    "    top_jobs = query_df.iloc[indices,:]\n",
    "    \n",
    "    top_index = indices[0]\n",
    "    if cosine_sim[top_index] < 0.25:\n",
    "        print('Jobs Are Not Very Similar')\n",
    "    elif cosine_sim[top_index] < 0.75:\n",
    "        print('Jobs Are Similar')\n",
    "    else: \n",
    "        print('Jobs Are Very Similar')\n",
    "    \n",
    "    return top_jobs[['job_title','company','state','city','url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_text = get_ideal_text(skill_set,ideal_url)\n",
    "\n",
    "df_ds = pd.read_csv('data_scientist.csv') \n",
    "df_mle = pd.read_csv('machine_learning_engineer.csv')\n",
    "df_sd = pd.read_csv('software_developer.csv')\n",
    "df_fsd = pd.read_csv('full_stack_developer.csv')\n",
    "df_bia = pd.read_csv('business_intelligence_analyst.csv')\n",
    "df_de = pd.read_csv('data_engineer.csv')\n",
    "df_da = pd.read_csv('data_architect.csv')\n",
    "df_py = pd.read_csv('python.csv')\n",
    "df_devops = pd.read_csv('dev_ops.csv')\n",
    "df_se = pd.read_csv('software_engineer.csv')\n",
    "\n",
    "dfList = [df_ds,df_mle,df_sd,df_fsd,df_bia,df_de,df_da,df_py,df_devops,df_se]\n",
    "joint_df = join_dfs(dfList)\n",
    "formatted_df = format_df(joint_df)\n",
    "#fix this an input \n",
    "query_df = get_query_df(formatted_df,'Data Scientist',city = 'New York',state = 'NY',skills = 'python',stringency='only')\n",
    "#fix num as input \n",
    "cosine_sim, indices =  get_top_sim(ideal_text, query_df,10)\n",
    "\n",
    "#figure out how you want to output this \n",
    "top_df = get_top_jobs(query_df, indices,cosine_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do \n",
    "- How do i speed up the stemming "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
